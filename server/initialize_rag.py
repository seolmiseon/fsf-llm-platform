"""
RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸

Football-Data APIì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì„œ 
ChromaDBì— ë²¡í„°í™”í•´ì„œ ì €ì¥í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ğŸ“– ì‹¤í–‰ ë°©ë²•:
    cd ~/fsf-llm-platform/server
    python initialize_rag.py

âš ï¸ ì£¼ì˜:
    - OpenAI API í‚¤ í•„ìš” (.env íŒŒì¼)
    - Football-Data API í‚¤ í•„ìš” (.env íŒŒì¼)
    - ì„ë² ë”© ìƒì„± ì¤‘ ë¹„ìš© ë°œìƒ (ë§¤ìš° ì ìŒ)
    - ì²« ì‹¤í–‰ ì‹œ 5-10ë¶„ ì†Œìš”
"""

import asyncio
import logging
import sys
import os
from datetime import datetime
from pathlib import Path

# ============================================
# â­ï¸ í™˜ê²½ ì„¤ì • (ê°€ì¥ ë¨¼ì €!)
# ============================================

# 1. ì˜¬ë°”ë¥¸ ê²½ë¡œ ì„¤ì •
script_dir = Path(__file__).parent.absolute()
os.chdir(script_dir)

print(f"ğŸ”§ ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •: {os.getcwd()}")

# 2. .env íŒŒì¼ ëª…ì‹œì ìœ¼ë¡œ ë¡œë“œ
from dotenv import load_dotenv

env_path = script_dir / ".env"
print(f"ğŸ“ .env íŒŒì¼ ê²½ë¡œ: {env_path}")
print(f"   íŒŒì¼ ì¡´ì¬: {'âœ… ì˜ˆ' if env_path.exists() else 'âŒ ì•„ë‹ˆì˜¤'}")

loaded = load_dotenv(env_path)
print(f"ğŸ“¥ .env ë¡œë“œ: {'âœ… ì„±ê³µ' if loaded else 'âš ï¸ ì°¾ì§€ ëª»í•¨ (ê¸°ë³¸ê°’ ì‚¬ìš©)'}")

# 3. í™˜ê²½ë³€ìˆ˜ í™•ì¸
print(f"\nğŸ”‘ í™˜ê²½ë³€ìˆ˜ í™•ì¸:")
print(f"   OPENAI_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('OPENAI_API_KEY') else 'âŒ ë¯¸ì„¤ì •'}")
print(f"   FOOTBALL_DATA_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('FOOTBALL_DATA_API_KEY') else 'âŒ ë¯¸ì„¤ì •'}")

# 4. ê²½ë¡œì— í˜„ì¬ ë””ë ‰í† ë¦¬ ì¶”ê°€ (import ë•Œë¬¸ì—)
if str(script_dir) not in sys.path:
    sys.path.insert(0, str(script_dir))

# ============================================
# ì„œë¹„ìŠ¤ ì„í¬íŠ¸
# ============================================

try:
    from llm_service.services.openai_service import OpenAIService
    from llm_service.services.rag_service import RAGService
    from llm_service.services.data_ingestion import DataIngestionService
    from llm_service.external_apis.football_data import FootballDataClient
    print("âœ… ì„œë¹„ìŠ¤ ì„í¬íŠ¸ ì„±ê³µ\n")
except ImportError as e:
    print(f"âŒ ì„œë¹„ìŠ¤ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    sys.exit(1)

# ============================================
# ë¡œê¹… ì„¤ì •
# ============================================

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)-8s | %(name)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(script_dir / "rag_initialization.log")
    ]
)

logger = logging.getLogger(__name__)

# ============================================
# 1. ì´ˆê¸°í™” í•¨ìˆ˜
# ============================================

def init_services():
    """
    ëª¨ë“  ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    
    Returns:
        (football_client, openai_service, rag_service, data_ingestion)
    """
    logger.info("=" * 60)
    logger.info("ğŸš€ RAG ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘")
    logger.info("=" * 60)
    
    try:
        logger.info("ğŸ“¦ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
        
        # 1. Football-Data API í´ë¼ì´ì–¸íŠ¸
        football_client = FootballDataClient()
        logger.info("âœ… Football-Data í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”")
        
        # 2. OpenAI ì„œë¹„ìŠ¤
        openai_service = OpenAIService()
        logger.info("âœ… OpenAI ì„œë¹„ìŠ¤ ì´ˆê¸°í™”")
        
        # 3. RAG ì„œë¹„ìŠ¤
        rag_service = RAGService()
        logger.info("âœ… RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™”")
        
        # 4. ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤
        data_ingestion = DataIngestionService(football_client, openai_service)
        logger.info("âœ… ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”")
        
        logger.info("ğŸ‰ ëª¨ë“  ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ!\n")
        
        return football_client, openai_service, rag_service, data_ingestion
        
    except Exception as e:
        logger.error(f"âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
        sys.exit(1)


async def load_matches_data(
    rag_service: RAGService,
    data_ingestion: DataIngestionService,
    competitions: list = ["PL", "LA", "BL"],
    days_back: int = 30,
    limit: int = 100
):
    """
    ê²½ê¸° ë°ì´í„° ìˆ˜ì§‘ ë° ë¡œë“œ
    
    Args:
        rag_service: RAG ì„œë¹„ìŠ¤
        data_ingestion: ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤
        competitions: ë¦¬ê·¸ ì½”ë“œ
        days_back: ë©°ì¹  ì „ê¹Œì§€ì˜ ê²½ê¸°
        limit: ìµœëŒ€ ê²½ê¸° ìˆ˜
    """
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š ê²½ê¸° ë°ì´í„° ë¡œë“œ")
    logger.info("=" * 60)
    
    try:
        all_match_docs = []
        
        for comp in competitions:
            logger.info(f"\nğŸ”„ {comp} ê²½ê¸° ìˆ˜ì§‘ ì¤‘... (ìµœê·¼ {days_back}ì¼)")
            
            # ê²½ê¸° ë°ì´í„° ìˆ˜ì§‘
            match_docs = await data_ingestion.ingest_recent_matches(
                competition=comp,
                days_back=days_back,
                limit=limit
            )
            
            if match_docs:
                logger.info(f"âœ… {comp}: {len(match_docs)}ê°œ ê²½ê¸° ìˆ˜ì§‘")
                all_match_docs.extend(match_docs)
            else:
                logger.warning(f"âš ï¸ {comp}: ê²½ê¸° ë°ì´í„° ì—†ìŒ")
        
        if all_match_docs:
            logger.info(f"\nğŸ“¥ ì´ {len(all_match_docs)}ê°œ ê²½ê¸°ë¥¼ ChromaDBì— ì €ì¥ ì¤‘...")
            
            # ë¬¸ì„œ, ë©”íƒ€ë°ì´í„°, ID ë¶„ë¦¬
            documents = [doc["document"] for doc in all_match_docs]
            metadatas = [doc["metadata"] for doc in all_match_docs]
            ids = [doc["id"] for doc in all_match_docs]
            
            # RAGì— ì €ì¥
            rag_service.add_documents(
                collection_name="matches",
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            
            logger.info(f"âœ… ê²½ê¸° ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
            logger.info(f"ğŸ“Š í˜„ì¬ matches ì»¬ë ‰ì…˜: {len(documents)}ê°œ ë¬¸ì„œ")
            
        else:
            logger.warning("âš ï¸ ë¡œë“œí•  ê²½ê¸° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            
    except Exception as e:
        logger.error(f"âŒ ê²½ê¸° ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)


async def load_standings_data(
    rag_service: RAGService,
    data_ingestion: DataIngestionService,
    competitions: list = ["PL", "LA", "BL"]
):
    """
    ìˆœìœ„í‘œ ë°ì´í„° ìˆ˜ì§‘ ë° ë¡œë“œ
    
    Args:
        rag_service: RAG ì„œë¹„ìŠ¤
        data_ingestion: ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤
        competitions: ë¦¬ê·¸ ì½”ë“œ
    """
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š ìˆœìœ„í‘œ ë°ì´í„° ë¡œë“œ")
    logger.info("=" * 60)
    
    try:
        logger.info(f"ğŸ”„ ìˆœìœ„í‘œ ìˆ˜ì§‘ ì¤‘... ({', '.join(competitions)})")
        
        # ìˆœìœ„í‘œ ë°ì´í„° ìˆ˜ì§‘
        standing_docs = await data_ingestion.ingest_standings(competitions)
        
        if standing_docs:
            logger.info(f"âœ… {len(standing_docs)}ê°œ ìˆœìœ„ ë°ì´í„° ìˆ˜ì§‘")
            
            logger.info(f"ğŸ“¥ ìˆœìœ„í‘œë¥¼ ChromaDBì— ì €ì¥ ì¤‘...")
            
            # ë¬¸ì„œ, ë©”íƒ€ë°ì´í„°, ID ë¶„ë¦¬
            documents = [doc["document"] for doc in standing_docs]
            metadatas = [doc["metadata"] for doc in standing_docs]
            ids = [doc["id"] for doc in standing_docs]
            
            # RAGì— ì €ì¥
            rag_service.add_documents(
                collection_name="standings",
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            
            logger.info(f"âœ… ìˆœìœ„í‘œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
            logger.info(f"ğŸ“Š í˜„ì¬ standings ì»¬ë ‰ì…˜: {len(documents)}ê°œ ë¬¸ì„œ")
            
        else:
            logger.warning("âš ï¸ ë¡œë“œí•  ìˆœìœ„í‘œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            
    except Exception as e:
        logger.error(f"âŒ ìˆœìœ„í‘œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)


async def load_teams_data(
    rag_service: RAGService,
    data_ingestion: DataIngestionService,
    competitions: list = ["PL"]
):
    """
    íŒ€ ì •ë³´ ë°ì´í„° ìˆ˜ì§‘ ë° ë¡œë“œ
    
    Args:
        rag_service: RAG ì„œë¹„ìŠ¤
        data_ingestion: ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤
        competitions: ë¦¬ê·¸ ì½”ë“œ (íŒ€ ì •ë³´ëŠ” ë¦¬ê·¸ë³„ë¡œ ìˆ˜ì§‘)
    """
    logger.info("\n" + "=" * 60)
    logger.info("âš½ íŒ€ ì •ë³´ ë°ì´í„° ë¡œë“œ")
    logger.info("=" * 60)
    
    try:
        all_team_docs = []
        
        for comp in competitions:
            logger.info(f"\nğŸ”„ {comp} íŒ€ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
            
            # íŒ€ ì •ë³´ ìˆ˜ì§‘
            team_docs = await data_ingestion.ingest_teams(comp)
            
            if team_docs:
                logger.info(f"âœ… {comp}: {len(team_docs)}ê°œ íŒ€ ì •ë³´ ìˆ˜ì§‘")
                all_team_docs.extend(team_docs)
            else:
                logger.warning(f"âš ï¸ {comp}: íŒ€ ì •ë³´ ì—†ìŒ")
        
        if all_team_docs:
            logger.info(f"\nğŸ“¥ ì´ {len(all_team_docs)}ê°œ íŒ€ ì •ë³´ë¥¼ ChromaDBì— ì €ì¥ ì¤‘...")
            
            # ë¬¸ì„œ, ë©”íƒ€ë°ì´í„°, ID ë¶„ë¦¬
            documents = [doc["document"] for doc in all_team_docs]
            metadatas = [doc["metadata"] for doc in all_team_docs]
            ids = [doc["id"] for doc in all_team_docs]
            
            # RAGì— ì €ì¥
            rag_service.add_documents(
                collection_name="teams",
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            
            logger.info(f"âœ… íŒ€ ì •ë³´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
            logger.info(f"ğŸ“Š í˜„ì¬ teams ì»¬ë ‰ì…˜: {len(documents)}ê°œ ë¬¸ì„œ")
            
        else:
            logger.warning("âš ï¸ ë¡œë“œí•  íŒ€ ì •ë³´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            
    except Exception as e:
        logger.error(f"âŒ íŒ€ ì •ë³´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)


def print_summary(rag_service: RAGService):
    """
    ì´ˆê¸°í™” ì™„ë£Œ ìš”ì•½ ì¶œë ¥
    
    Args:
        rag_service: RAG ì„œë¹„ìŠ¤
    """
    logger.info("\n" + "=" * 60)
    logger.info("âœ… RAG ì´ˆê¸°í™” ì™„ë£Œ!")
    logger.info("=" * 60)
    
    try:
        logger.info("\nğŸ“Š ë°ì´í„° í†µê³„:")
        total_docs = 0
        
        # ChromaDB ì»¬ë ‰ì…˜ í†µê³„
        collections_to_check = ["matches", "standings", "teams"]
        
        for collection_name in collections_to_check:
            try:
                stats = rag_service.get_collection_stats(collection_name)
                count = stats["count"]
                total_docs += count
                logger.info(f"  - {collection_name}: {count}ê°œ ë¬¸ì„œ")
            except:
                logger.info(f"  - {collection_name}: ë°ì´í„° ì—†ìŒ")
        
        logger.info(f"\nğŸ“ˆ ì´ {total_docs}ê°œ ë¬¸ì„œê°€ ChromaDBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        logger.info("\nğŸ§ª í…ŒìŠ¤íŠ¸ ë°©ë²•:")
        logger.info("  $ curl -X POST 'http://localhost:8000/api/llm/chat' \\")
        logger.info("      -H 'Content-Type: application/json' \\")
        logger.info("      -d '{\"query\": \"Arsenal ìµœê·¼ ê²½ê¸°\", \"top_k\": 5}'")
        
        logger.info("\nğŸ’¾ ë°ì´í„° ì €ì¥ ìœ„ì¹˜:")
        logger.info(f"  {rag_service.persist_dir}")
        
        logger.info("\n" + "=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")


# ============================================
# 2. ë©”ì¸ í•¨ìˆ˜
# ============================================

async def main():
    """
    RAG ì´ˆê¸°í™” ë©”ì¸ í•¨ìˆ˜
    """
    start_time = datetime.now()
    
    try:
        # 1. ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        football_client, openai_service, rag_service, data_ingestion = init_services()
        
        # 2. ë°ì´í„° ë¡œë“œ
        await load_matches_data(rag_service, data_ingestion)
        await load_standings_data(rag_service, data_ingestion)
        await load_teams_data(rag_service, data_ingestion)
        
        # 3. ìš”ì•½ ì¶œë ¥
        print_summary(rag_service)
        
        # ì†Œìš” ì‹œê°„
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        logger.info(f"\nâ±ï¸  ì†Œìš” ì‹œê°„: {duration:.1f}ì´ˆ")
        
    except Exception as e:
        logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())