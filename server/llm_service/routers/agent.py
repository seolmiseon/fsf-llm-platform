"""
Agent ì—”ë“œí¬ì¸íŠ¸
POST /api/llm/agent
"""
from fastapi import APIRouter, HTTPException
from typing import List
import logging
from datetime import datetime

from ..models import AgentRequest, AgentResponse, ErrorResponse, ChatRequest, ChatResponse
from ..services.openai_service import OpenAIService
from ..services.content_safety_service import ContentSafetyService
from ..services.cache_service import CacheService
from ..tools import (
    RAGSearchTool,
    MatchAnalysisTool,
    PlayerCompareTool,
    PostsSearchTool,
)
from ..utils.question_classifier import is_complex_question
from ..routers.chat import chat as chat_endpoint  # ê¸°ì¡´ chat ì—”ë“œí¬ì¸íŠ¸ í•¨ìˆ˜
from langchain.agents import initialize_agent, AgentType
from langchain_openai import ChatOpenAI
import os

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/agent", tags=["AI Agent"])

# ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
openai_service = OpenAIService()

# CacheService ì´ˆê¸°í™”
try:
    cache_service = CacheService()
except Exception as e:
    logger.warning(f"âš ï¸ CacheService ì´ˆê¸°í™” ì‹¤íŒ¨ (ìºì‹œ ê¸°ëŠ¥ ë¹„í™œì„±í™”): {e}")
    cache_service = None

# Content Safety Service ì´ˆê¸°í™”
try:
    content_safety_service = ContentSafetyService()
except Exception as e:
    logger.warning(f"âš ï¸ ContentSafetyService ì´ˆê¸°í™” ì‹¤íŒ¨ (í•„í„°ë§ ê¸°ëŠ¥ ë¹„í™œì„±í™”): {e}")
    content_safety_service = None

# LangChain LLM ì´ˆê¸°í™”
llm = ChatOpenAI(
    model=os.getenv("OPENAI_CHAT_MODEL", "gpt-4o-mini"),
    temperature=0.7
)

# Tool ë¦¬ìŠ¤íŠ¸
tools = [
    RAGSearchTool,
    MatchAnalysisTool,
    PlayerCompareTool,
    PostsSearchTool,
]

# Agent ì´ˆê¸°í™”
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    handle_parsing_errors=True
)

# Agent ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
AGENT_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì¶•êµ¬ ë¶„ì„ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ì‚¬ìš©í•˜ì„¸ìš”.

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
1. rag_search: ì¶•êµ¬ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ (ì„ ìˆ˜, íŒ€, ê²½ê¸°, í†µê³„ ë“±)
2. match_analysis: ê²½ê¸° ë¶„ì„ (ê²½ê¸° ID í•„ìš”)
3. player_compare: ì„ ìˆ˜ ë¹„êµ ë¶„ì„ (2ëª… ì´ìƒì˜ ì„ ìˆ˜ ì´ë¦„ í•„ìš”)
4. posts_search: ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œíŒì—ì„œ í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ê²Œì‹œê¸€ì„ ì°¾ì•„ì£¼ëŠ” ë„êµ¬ (ì˜ˆ: "ì†í¥ë¯¼ ê´€ë ¨ ê¸€", "ì»¤ë®¤ë‹ˆí‹° ê¸€ ì¶”ì²œ" ë“±)

í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."""


@router.post(
    "",
    response_model=AgentResponse,
    responses={
        200: {"description": "Agent ì‘ë‹µ ì„±ê³µ"},
        400: {"model": ErrorResponse, "description": "ì˜ëª»ëœ ìš”ì²­"},
        500: {"model": ErrorResponse, "description": "ì„œë²„ ì˜¤ë¥˜"},
    },
)
async def agent_chat(request: AgentRequest) -> AgentResponse:
    """
    AI Agent ì—”ë“œí¬ì¸íŠ¸
    
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ì„œ ì ì ˆí•œ Toolì„ ìë™ìœ¼ë¡œ ì„ íƒí•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    Args:
        request: AgentRequest
            - query: ì‚¬ìš©ì ì§ˆë¬¸
            - context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (ì„ íƒ)
    
    Returns:
        AgentResponse: AI ë‹µë³€ + ì‚¬ìš©ëœ Tool ëª©ë¡
    """
    try:
        logger.info(f"ğŸ¤– Agent ìš”ì²­: {request.query}")

        # ============================================
        # ğŸ›¡ï¸ STEP 1: ì…ë ¥ ê²Œì´íŠ¸ì›¨ì´ - ì‚¬ìš©ì ì¿¼ë¦¬ í•„í„°ë§
        # ============================================
        if content_safety_service:
            logger.debug("ğŸ›¡ï¸ ì…ë ¥ í•„í„°ë§ ì¤‘...")
            input_check = content_safety_service.check_input(request.query)
            
            if not input_check.is_safe:
                logger.warning(
                    f"ğŸš« ìœ í•´ ì½˜í…ì¸  ê°ì§€ (ì…ë ¥): "
                    f"ì¹´í…Œê³ ë¦¬={input_check.category}, "
                    f"ê°ì§€ëœ ë‹¨ì–´={input_check.detected_words}"
                )
                raise HTTPException(
                    status_code=400,
                    detail={
                        "error": "ë¶€ì ì ˆí•œ ë‚´ìš©ì´ í¬í•¨ëœ ìš”ì²­ì…ë‹ˆë‹¤.",
                        "error_code": "INAPPROPRIATE_CONTENT",
                        "category": input_check.category.value if input_check.category else None,
                        "reason": input_check.reason
                    }
                )
            logger.debug("âœ… ì…ë ¥ í•„í„°ë§ í†µê³¼")

        # ============================================
        # âœ… STEP 2: ë‹¨ìˆœ/ë³µì¡ ì§ˆë¬¸ íŒë‹¨ ë° ë¶„ê¸°
        # ============================================
        is_complex = is_complex_question(request.query)
        
        if not is_complex:
            # ë‹¨ìˆœ ì§ˆë¬¸ â†’ ê¸°ì¡´ chat.py ë¡œì§ ì‚¬ìš© (ë¹„ìš© ì ˆê°)
            logger.info("ğŸ’° ë‹¨ìˆœ ì§ˆë¬¸ ê°ì§€ â†’ ê¸°ì¡´ chat.py ë¡œì§ ì‚¬ìš© (LLM 1íšŒ í˜¸ì¶œ)")
            chat_request = ChatRequest(query=request.query, top_k=5)
            chat_response = await chat_endpoint(chat_request)
            
            # ChatResponseë¥¼ AgentResponseë¡œ ë³€í™˜
            return AgentResponse(
                answer=chat_response.answer,
                tools_used=["rag_search"],  # chat.pyëŠ” ê¸°ë³¸ì ìœ¼ë¡œ RAG ê²€ìƒ‰ ì‚¬ìš©
                tokens_used=chat_response.tokens_used,
                confidence=chat_response.confidence
            )
        
        # ë³µì¡í•œ ì§ˆë¬¸ â†’ Agent ë¡œì§ ì‚¬ìš©
        logger.info("ğŸ¤– ë³µì¡í•œ ì§ˆë¬¸ ê°ì§€ â†’ Agent ë¡œì§ ì‚¬ìš© (LLM 2íšŒ ì´ìƒ í˜¸ì¶œ)")
        
        # ë³µì¡í•œ ì§ˆë¬¸ì€ ìºì‹œë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì •í™•ë„ ìš°ì„ )
        # ë‹¨, ëª…ì‹œì ìœ¼ë¡œ ìºì‹œ í‚¤ë¡œ ì €ì¥ëœ ê²½ìš°ë§Œ í™•ì¸
        # (ì¼ë°˜ ë²¡í„° ê²€ìƒ‰ì€ ìœ ì‚¬ë„ê°€ ë‚®ì•„ë„ ë§¤ì¹­ë  ìˆ˜ ìˆì–´ì„œ ìœ„í—˜)
        logger.debug("âš ï¸ ë³µì¡í•œ ì§ˆë¬¸ì€ ìºì‹œ ìŠ¤í‚µ (ì •í™•ë„ ìš°ì„ )")
        
        # ============================================
        # âœ… STEP 3: Agent ì‹¤í–‰
        # ============================================
        logger.debug("ğŸ¤– Agent ì‹¤í–‰ ì¤‘...")
        
        # Agent ì‹¤í–‰ (ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)
        import asyncio
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            None,
            lambda: agent.run(AGENT_SYSTEM_PROMPT + "\n\nì‚¬ìš©ì ì§ˆë¬¸: " + request.query)
        )

        # ============================================
        # ğŸ›¡ï¸ STEP 4: ì¶œë ¥ í•„í„° - LLM ì‘ë‹µ í•„í„°ë§
        # ============================================
        if content_safety_service:
            logger.debug("ğŸ›¡ï¸ ì¶œë ¥ í•„í„°ë§ ì¤‘...")
            output_check = content_safety_service.check_output(result)
            
            if not output_check.is_safe:
                logger.warning(
                    f"ğŸš« ìœ í•´ ì½˜í…ì¸  ê°ì§€ (ì¶œë ¥): "
                    f"ì¹´í…Œê³ ë¦¬={output_check.category}, "
                    f"ê°ì§€ëœ ë‹¨ì–´={output_check.detected_words}"
                )
                # ìœ í•´ ì½˜í…ì¸ ê°€ ê°ì§€ë˜ë©´ í•„í„°ë§ëœ í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´
                result = content_safety_service.filter_text(result)
                logger.info("âœ… ì¶œë ¥ í•„í„°ë§ ì ìš© (ìœ í•´ ì½˜í…ì¸  ë§ˆìŠ¤í‚¹)")

        # ============================================
        # âœ… STEP 5: ì‚¬ìš©ëœ Tool ì¶”ì¶œ (ê°„ë‹¨í•œ ì¶”ì •)
        # ============================================
        # Agentê°€ ì‚¬ìš©í•œ Toolì€ ë¡œê·¸ì—ì„œ í™•ì¸ ê°€ëŠ¥í•˜ì§€ë§Œ,
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•˜ê²Œ ì§ˆë¬¸ ë‚´ìš©ìœ¼ë¡œ ì¶”ì •
        tools_used = []
        query_lower = request.query.lower()
        if "ì»¤ë®¤ë‹ˆí‹°" in query_lower or "ê²Œì‹œíŒ" in query_lower or "ê²Œì‹œê¸€" in query_lower or "ê¸€" in query_lower:
            tools_used.append("posts_search")
        if "ê²½ê¸°" in query_lower or "match" in query_lower:
            tools_used.append("match_analysis")
        if "ë¹„êµ" in query_lower or "compare" in query_lower:
            tools_used.append("player_compare")
        if not tools_used:
            tools_used.append("rag_search")  # ê¸°ë³¸ì ìœ¼ë¡œ RAG ê²€ìƒ‰ ì‚¬ìš©

        # í† í° ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ ì¶”ì •)
        tokens_used = openai_service.count_tokens(request.query) + openai_service.count_tokens(result)

        logger.info(f"âœ… Agent ì‘ë‹µ ìƒì„± ì™„ë£Œ (ì‚¬ìš©ëœ Tool: {', '.join(tools_used)})")

        # ============================================
        # âœ… STEP 6: Agent ê²°ê³¼ ìºì‹±
        # ============================================
        if cache_service:
            await cache_service.cache_answer(
                query=f"agent:{request.query}",
                answer=result,
                metadata={
                    "tools_used": tools_used,
                    "model": "gpt-4o-mini",
                    "tokens": tokens_used,
                },
            )
            logger.info("âœ… Agent ê²°ê³¼ ìºì‹œ ì €ì¥ ì™„ë£Œ")

        return AgentResponse(
            answer=result,
            tools_used=tools_used,
            tokens_used=tokens_used,
            confidence=0.85
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Agent ì˜¤ë¥˜: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Agent ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")


@router.get("/health", response_model=dict, summary="Agent ì„œë¹„ìŠ¤ í—¬ìŠ¤ ì²´í¬")
async def agent_health():
    """Agent ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    return {
        "status": "healthy",
        "service": "agent",
        "tools_count": len(tools),
        "tools": [tool.name for tool in tools],
        "timestamp": datetime.now().isoformat(),
    }

