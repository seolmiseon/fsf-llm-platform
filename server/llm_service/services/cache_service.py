from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import logging
import hashlib
import os

from .rag_service import RAGService
from ..utils.keyword_matcher import calculate_keyword_match, should_skip_judge_by_keyword

logger = logging.getLogger(__name__)


class CacheService:
    """
    í†µí•© ìºì‹œ ì„œë¹„ìŠ¤

    âœ… ChromaDB: LLM ë‹µë³€ ìºì‹œ
    âœ… Firestore: API ë°ì´í„° ìºì‹œ
    """

    def __init__(self):
        """
        ìºì‹œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        """
        self.rag_service = None
        self.cache_rag = None
        self._db = None
        
        try:
            self.rag_service = RAGService(persist_directory="chroma_db")
            self.cache_rag = RAGService(persist_directory="chroma_db_cache")
            logger.info("âœ… CacheService ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸ ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨ (ìºì‹œ ê¸°ëŠ¥ ë¹„í™œì„±í™”): {e}")
            logger.warning("ğŸ’¡ í•´ê²° ë°©ë²•: ChromaDB ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚­ì œí•˜ê³  ì¬ìƒì„±í•˜ì„¸ìš”.")
            logger.warning("   rm -rf chroma_db chroma_db_cache")
            # ChromaDB ì‹¤íŒ¨í•´ë„ ì„œë¹„ìŠ¤ëŠ” ê³„ì† ì‹¤í–‰ (ìºì‹œ ì—†ì´)

    @property
    def db(self):
        """Firestore DB ì§€ì—° ë¡œë”©"""
        if self._db is None:
            try:
                from firebase_admin import firestore

                self._db = firestore.client()
                logger.info("âœ… Firestore í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”")
            except Exception as e:
                logger.warning(f"âš ï¸ Firestore ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self._db = None
        return self._db

    # ============================================
    # PART 1: ChromaDB ë‹µë³€ ìºì‹œ
    # ============================================
    
    # LLM ë‹µë³€ ìºì‹œ TTL (ì¼) - í˜„ì—…ì—ì„œëŠ” ë³´í†µ 7-30ì¼
    LLM_CACHE_TTL_DAYS = 7  # 7ì¼ í›„ ìë™ ë§Œë£Œ

    async def get_cached_answer(self, query: str) -> Optional[dict]:
        """
        ChromaDBì—ì„œ ìœ ì‚¬í•œ ë‹µë³€ ê²€ìƒ‰

        ë¹„ìš©: $0 (ë¬¸ì„œ ê²€ìƒ‰ë§Œ, LLM í˜¸ì¶œ ì—†ìŒ!)

        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸

        Returns:
            {
                "answer": "...",
                "confidence": 0.95,
                "similarity": 0.98,
                "source": "chromadb_cache"
            } ë˜ëŠ” None (ìºì‹œ ë¯¸ìŠ¤)

        Example:
            >>> cached = await cache_service.get_cached_answer("ì†í¥ë¯¼ í¼?")
            >>> if cached:
            ...     print(cached["answer"])
        """
        if not self.cache_rag:
            return None
            
        try:
            normalized = self._normalize_query(query)

            results = self.cache_rag.search(
                collection_name="cached_answers", query=normalized, top_k=1
            )

            logger.info(f"ğŸ” ìºì‹œ ê²€ìƒ‰ ê²°ê³¼: {len(results.get('ids', []))}ê°œ ë°œê²¬")
            logger.info(f"ğŸ” ê²€ìƒ‰ëœ IDs: {results.get('ids', [])}")

            if not results["ids"] or len(results["ids"]) == 0:
                logger.debug(f"âš ï¸ ìºì‹œ ë¯¸ìŠ¤: {query[:50]}")
                return None
            ...

            # ìœ ì‚¬ë„ ê³„ì‚° (ê±°ë¦¬ â†’ ìœ ì‚¬ë„)
            distance = results["distances"][0]
            similarity = 1 - distance

            # ìœ ì‚¬ë„ ì„ê³„ê°’ (ì„¤ì • ê°€ëŠ¥)
            # 0.85: ì—„ê²©í•œ ê¸°ì¤€ (ì œì•ˆëœ ê°’)
            # 0.7~0.75: ê· í˜•ì¡íŒ ê¸°ì¤€ (ê¶Œì¥)
            SIMILARITY_THRESHOLD = float(os.getenv("CACHE_SIMILARITY_THRESHOLD", "0.75"))
            
            # ìœ ì‚¬ë„ ì„ê³„ê°’ ì´ìƒ: ìºì‹œ í›„ë³´ (Judge ë…¸ë“œì—ì„œ ìµœì¢… íŒë‹¨)
            if similarity >= SIMILARITY_THRESHOLD:
                # TTL ì²´í¬: ë§Œë£Œëœ ìºì‹œëŠ” ë¬´ì‹œ
                metadata = results["metadatas"][0] if results.get("metadatas") else {}
                created_at_str = metadata.get("created_at")
                
                if created_at_str:
                    try:
                        # ISO í¬ë§· íŒŒì‹± (íƒ€ì„ì¡´ ì œê±°)
                        created_at_str_clean = created_at_str.split('+')[0].split('Z')[0]
                        created_at = datetime.fromisoformat(created_at_str_clean)
                        # íƒ€ì„ì¡´ ì œê±° (naive datetimeìœ¼ë¡œ í†µì¼)
                        if created_at.tzinfo:
                            created_at = created_at.replace(tzinfo=None)
                        
                        now = datetime.now()
                        age_days = (now - created_at).days
                        
                        if age_days > self.LLM_CACHE_TTL_DAYS:
                            logger.info(
                                f"â° ìºì‹œ ë§Œë£Œ: '{query[:50]}...' ({age_days}ì¼ ê²½ê³¼, TTL: {self.LLM_CACHE_TTL_DAYS}ì¼)"
                            )
                            return None
                        else:
                            logger.debug(f"âœ… ìºì‹œ ìœ íš¨: {age_days}ì¼ ê²½ê³¼ (TTL: {self.LLM_CACHE_TTL_DAYS}ì¼)")
                    except (ValueError, AttributeError, TypeError) as e:
                        logger.debug(f"âš ï¸ ìºì‹œ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {e}, ìºì‹œ ì‚¬ìš© ê³„ì†")

                # ============================================
                # ğŸ†• Keyword ê²€ìƒ‰ ì¶”ê°€ (ì œë¯¼ì˜ ì œì•ˆ 2: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰)
                # ============================================
                cached_answer_text = results["documents"][0]
                keyword_score = calculate_keyword_match(query, cached_answer_text)
                
                # Keyword ì ìˆ˜ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ Judge ìŠ¤í‚µ, API í˜¸ì¶œ
                KEYWORD_THRESHOLD = float(os.getenv("KEYWORD_MATCH_THRESHOLD", "0.5"))
                if should_skip_judge_by_keyword(keyword_score, KEYWORD_THRESHOLD):
                    logger.info(
                        f"ğŸ” Keyword ì ìˆ˜ ë‚®ìŒ ({keyword_score:.2f} < {KEYWORD_THRESHOLD}) "
                        f"â†’ ìºì‹œ ë¬´ì‹œ, API í˜¸ì¶œ"
                    )
                    return None
                
                logger.info(
                    f"ğŸ¯ ChromaDB ìºì‹œ íˆíŠ¸: '{query[:50]}...' "
                    f"(ìœ ì‚¬ë„ {similarity:.2f}, Keyword {keyword_score:.2f})"
                )

                return {
                    "answer": cached_answer_text,
                    "confidence": similarity,
                    "similarity": similarity,
                    "keyword_score": keyword_score,  # ğŸ†• Keyword ì ìˆ˜ ì¶”ê°€
                    "source": "chromadb_cache",
                }
            else:
                logger.debug(f"âš ï¸ ìœ ì‚¬ë„ ë¶€ì¡±: {similarity:.2f} < {SIMILARITY_THRESHOLD}")
                return None

        except Exception as e:
            logger.warning(f"âš ï¸ ChromaDB ìºì‹œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None

    async def cache_answer(
        self, query: str, answer: str, metadata: Optional[dict] = None
    ) -> bool:
        """
        ë‹µë³€ì„ ChromaDBì— ì €ì¥
        (ë‹¤ìŒ ìœ ì‚¬ì§ˆë¬¸ ì‹œ ì¬ì‚¬ìš©)

        ë¹„ìš©: $0 (ì €ì¥ë§Œ, LLM í˜¸ì¶œ ì—†ìŒ!)

        Args:
            query: ì›ë³¸ ì§ˆë¬¸
            answer: LLM ë‹µë³€
            metadata: ì¶”ê°€ ì •ë³´ (RAG ì†ŒìŠ¤, ëª¨ë¸ëª…, í† í° ë“±)

        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€

        Example:
            >>> await cache_service.cache_answer(
            ...     "ì†í¥ë¯¼ í¼?",
            ...     "ì†í¥ë¯¼ì€ ìµœê·¼ 3ê³¨...",
            ...     metadata={"model": "gpt-4o-mini", "tokens": 350}
            ... )
        """
        if not self.cache_rag:
            return False
            
        try:
            normalized = self._normalize_query(query)

            # ê³ ìœ  ID ìƒì„± (ì¿¼ë¦¬ í•´ì‹œ)
            query_hash = hashlib.md5(normalized.encode()).hexdigest()
            doc_id = f"answer_{query_hash}"

            # metadataì—ì„œ ë¦¬ìŠ¤íŠ¸ ê°’ í•„í„°ë§ (ì¶”ê°€!)
            filtered_metadata = {}
            if metadata:
                for key, value in metadata.items():
                    # str, int, float, bool, Noneë§Œ í—ˆìš©
                    if isinstance(value, (str, int, float, bool, type(None))):
                        filtered_metadata[key] = value
                    elif isinstance(value, list):
                        # ë¦¬ìŠ¤íŠ¸ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
                        filtered_metadata[key] = str(value)

            # ChromaDBì— ì €ì¥
            self.cache_rag.add_documents(
                collection_name="cached_answers",
                documents=[answer],
                metadatas=[
                    {
                        "original_query": query[:300],
                        "normalized_query": normalized,
                        "answer_preview": answer[:100],
                        "created_at": datetime.now().isoformat(),
                        "tokens_saved": 500,  # ì˜ˆìƒ ì ˆê° í† í°
                        **filtered_metadata,
                    }
                ],
                ids=[doc_id],
            )

            logger.info(f"âœ… ë‹µë³€ ìºì‹œ ì €ì¥: {query[:50]}... (ID: {doc_id})")
            return True

        except Exception as e:
            logger.error(f"âŒ ë‹µë³€ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    # ============================================
    # PART 2: Firestore API ë°ì´í„° ìºì‹œ
    # ============================================

    async def get_cached_api_data(self, api_type: str, params: dict) -> Optional[dict]:
        """
        Firestoreì—ì„œ API ìºì‹œ ê²€ìƒ‰

        ë¹„ìš©: $0 (ì¡°íšŒë§Œ, API í˜¸ì¶œ ì—†ìŒ!)

        Args:
            api_type: API ìœ í˜• ("football_standings", "football_matches" ë“±)
            params: íŒŒë¼ë¯¸í„° ({"competition": "PL"} ë“±)

        Returns:
            {
                "data": {...},
                "cached": True,
                "age_seconds": 120,
                "source": "firestore_cache"
            } ë˜ëŠ” None (ìºì‹œ ë¯¸ìŠ¤/ë§Œë£Œ)

        Example:
            >>> cached = await cache_service.get_cached_api_data(
            ...     "football_standings",
            ...     {"competition": "PL"}
            ... )
        """
        try:
            if not self.db:
                logger.warning("âš ï¸ Firestore ë¯¸ì—°ê²°, API ìºì‹œ ìŠ¤í‚µ")
                return None

            cache_key = self._generate_cache_key(api_type, params)

            cache_doc = self.db.collection("api_cache").document(cache_key).get()

            if not cache_doc.exists:
                logger.debug(f"âš ï¸ API ìºì‹œ ë¯¸ìŠ¤: {cache_key}")
                return None

            cache_data = cache_doc.to_dict()
            expires_at = cache_data.get("expires_at")

            # ìºì‹œ ë§Œë£Œ í™•ì¸
            if expires_at and expires_at < datetime.now():
                logger.info(f"ğŸ—‘ï¸ ë§Œë£Œëœ ìºì‹œ ì‚­ì œ: {cache_key}")
                try:
                    cache_doc.reference.delete()
                except:
                    pass
                return None

            # ìºì‹œ ë‚˜ì´ ê³„ì‚°
            created_at = cache_data.get("created_at")
            if created_at:
                age = (datetime.now() - created_at).total_seconds()
            else:
                age = 0

            logger.info(f"âœ… Firestore ìºì‹œ íˆíŠ¸: {cache_key} ({age:.0f}ì´ˆ ìºì‹œë¨)")

            return {
                "data": cache_data.get("payload"),
                "cached": True,
                "age_seconds": int(age),
                "source": "firestore_cache",
            }

        except Exception as e:
            logger.warning(f"âš ï¸ Firestore ìºì‹œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None

    async def cache_api_data(
        self, api_type: str, params: dict, data: dict, ttl_hours: int = 1
    ) -> bool:
        """
        API ì‘ë‹µì„ Firestoreì— ì €ì¥

        ë¹„ìš©: ì €ì¥ ë¹„ìš©ë§Œ (ë§¤ìš° ì €ë ´)

        Args:
            api_type: API ìœ í˜•
            params: íŒŒë¼ë¯¸í„°
            data: API ì‘ë‹µ ë°ì´í„°
            ttl_hours: ìºì‹œ ìœ íš¨ ì‹œê°„ (ì‹œê°„, ê¸°ë³¸ê°’: 1ì‹œê°„)

        Returns:
            ì €ì¥ ì„±ê³µ ì—¬ë¶€

        Example:
            >>> await cache_service.cache_api_data(
            ...     "football_standings",
            ...     {"competition": "PL"},
            ...     api_response_data,
            ...     ttl_hours=1
            ... )
        """
        try:
            if not self.db:
                logger.warning("âš ï¸ Firestore ë¯¸ì—°ê²°, API ìºì‹œ ì €ì¥ ìŠ¤í‚µ")
                return False

            cache_key = self._generate_cache_key(api_type, params)
            now = datetime.now()
            expires_at = now + timedelta(hours=ttl_hours)

            cache_doc = {
                "api_type": api_type,
                "params": params,
                "payload": data,
                "created_at": now,
                "expires_at": expires_at,
                "ttl_hours": ttl_hours,
            }

            self.db.collection("api_cache").document(cache_key).set(cache_doc)

            logger.info(f"âœ… API ìºì‹œ ì €ì¥: {cache_key} (TTL: {ttl_hours}ì‹œê°„)")
            return True

        except Exception as e:
            logger.error(f"âŒ API ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    # ============================================
    # PART 3: ìœ í‹¸ë¦¬í‹°
    # ============================================

    @staticmethod
    def _normalize_query(query: str) -> str:
        """
        ì§ˆë¬¸ ì •ê·œí™”
        - ê³µë°± ì œê±°
        - ì†Œë¬¸ì ë³€í™˜
        - ìµœëŒ€ 300ì ì œí•œ

        Args:
            query: ì›ë³¸ ì§ˆë¬¸

        Returns:
            ì •ê·œí™”ëœ ì§ˆë¬¸

        Example:
            >>> _normalize_query("  Arsenal ìµœê·¼ ê²½ê¸°  ")
            "arsenal ìµœê·¼ ê²½ê¸°"
        """
        return query.strip().lower()[:300]

    @staticmethod
    def _generate_cache_key(api_type: str, params: dict) -> str:
        """
        ìºì‹œ í‚¤ ìƒì„± (ê³ ìœ ì„± ë³´ì¥)

        ì˜ˆì‹œ:
        - "football_standings_pl"
        - "football_matches_pl_finished_10"

        Args:
            api_type: API ìœ í˜•
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬

        Returns:
            ìºì‹œ í‚¤

        Example:
            >>> _generate_cache_key("football_standings", {"competition": "PL"})
            "football_standings_competition_pl"
        """
        param_str = "_".join(f"{k}_{str(v).lower()}" for k, v in sorted(params.items()))
        key = f"{api_type}_{param_str}"
        return key.replace(".", "_").replace("-", "_").replace(" ", "_")

    # ============================================
    # PART 4: í†µê³„ & ëª¨ë‹ˆí„°ë§ (ë³´ë„ˆìŠ¤)
    # ============================================

    async def get_cache_stats(self) -> dict:
        """
        ìºì‹œ í†µê³„ ì¡°íšŒ

        Returns:
            {
                "chromadb_answers": 150,
                "firestore_cache": 45,
                "estimated_cost_saved": 12.50
            }
        """
        try:
            stats = {
                "chromadb_answers": 0,
                "firestore_cache": 0,
                "estimated_cost_saved": 0.0,
            }

            # ChromaDB í†µê³„
            try:
                answer_stats = self.rag_service.get_collection_stats("cached_answers")
                stats["chromadb_answers"] = answer_stats.get("count", 0)
            except:
                pass

            # Firestore í†µê³„
            if self.db:
                try:
                    cache_docs = list(self.db.collection("api_cache").stream())
                    stats["firestore_cache"] = len(cache_docs)
                except:
                    pass

            # ë¹„ìš© ì ˆê° ì¶”ì • (ë‹µë³€ ìºì‹œ Ã— $0.001 + API í˜¸ì¶œ $0.005)
            stats["estimated_cost_saved"] = (
                stats["chromadb_answers"] * 0.001 + stats["firestore_cache"] * 0.005
            )

            logger.info(f"ğŸ“Š ìºì‹œ í†µê³„: {stats}")
            return stats

        except Exception as e:
            logger.error(f"âŒ ìºì‹œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
